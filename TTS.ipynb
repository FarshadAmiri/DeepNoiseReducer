{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from TTS.api import TTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > tts_models/multilingual/multi-dataset/xtts_v2 is already downloaded.\n",
      " > Using model: xtts\n"
     ]
    }
   ],
   "source": [
    "# Load a multilingual TTS model\n",
    "tts = TTS(model_name=\"tts_models/multilingual/multi-dataset/xtts_v2\").to(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > Text splitted to sentences.\n",
      "['سلام، حال شما چطور است؟']\n",
      " > Processing time: 10.425678491592407\n",
      " > Real-time factor: 2.17398822381991\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\User_1\\\\Desktop\\\\persian_tts.wav'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "persian_output_path = r\"C:\\Users\\User_1\\Desktop\\persian_tts.wav\"\n",
    "arabic_output_path = r\"C:\\Users\\User_1\\Desktop\\arabic_tts.wav\"\n",
    "reference = r\"C:\\Users\\User_1\\Desktop\\obama.ogg\"\n",
    "\n",
    "# Convert text to speech in Persian\n",
    "tts.tts_to_file(text=\"سلام، حال شما چطور است؟\", file_path=persian_output_path, speaker_wav=reference, language=\"fa\")\n",
    "\n",
    "# Convert text to speech in Arabic\n",
    "# tts.tts_to_file(text=\"مرحبًا، كيف حالك؟\", file_path=arabic_output_path,\n",
    "#                 speaker_wav=reference, \n",
    "#                 language=\"ar\"\n",
    "#                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > Using model: vits\n",
      " > Setting up Audio Processor...\n",
      " | > sample_rate:22050\n",
      " | > resample:False\n",
      " | > num_mels:80\n",
      " | > log_func:np.log10\n",
      " | > min_level_db:0\n",
      " | > frame_shift_ms:None\n",
      " | > frame_length_ms:None\n",
      " | > ref_level_db:None\n",
      " | > fft_size:1024\n",
      " | > power:None\n",
      " | > preemphasis:0.0\n",
      " | > griffin_lim_iters:None\n",
      " | > signal_norm:None\n",
      " | > symmetric_norm:None\n",
      " | > mel_fmin:0\n",
      " | > mel_fmax:None\n",
      " | > pitch_fmin:None\n",
      " | > pitch_fmax:None\n",
      " | > spec_gain:20.0\n",
      " | > stft_pad_mode:reflect\n",
      " | > max_norm:1.0\n",
      " | > clip_norm:True\n",
      " | > do_trim_silence:False\n",
      " | > trim_db:60\n",
      " | > do_sound_norm:False\n",
      " | > do_amp_to_db_linear:True\n",
      " | > do_amp_to_db_mel:True\n",
      " | > do_rms_norm:False\n",
      " | > db_level:None\n",
      " | > stats_path:None\n",
      " | > base:10\n",
      " | > hop_length:256\n",
      " | > win_length:1024\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": " [!] No espeak backend found. Install espeak-ng or espeak to your system.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mException\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m tts\u001b[38;5;241m=\u001b[39m\u001b[43mTTS\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mhttps://huggingface.co/Kamtera/persian-tts-male1-vits/resolve/main/checkpoint_88000.pth\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfig_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mhttps://huggingface.co/Kamtera/persian-tts-male1-vits/resolve/main/config.json\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\Projects\\venv2\\lib\\site-packages\\TTS\\api.py:81\u001b[0m, in \u001b[0;36mTTS.__init__\u001b[1;34m(self, model_name, model_path, config_path, vocoder_path, vocoder_config_path, progress_bar, gpu)\u001b[0m\n\u001b[0;32m     78\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mload_model_by_name(model_name, gpu)\n\u001b[0;32m     80\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m model_path:\n\u001b[1;32m---> 81\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_tts_model_by_path\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     82\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvocoder_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvocoder_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvocoder_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvocoder_config_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgpu\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgpu\u001b[49m\n\u001b[0;32m     83\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\Projects\\venv2\\lib\\site-packages\\TTS\\api.py:203\u001b[0m, in \u001b[0;36mTTS.load_tts_model_by_path\u001b[1;34m(self, model_path, config_path, vocoder_path, vocoder_config, gpu)\u001b[0m\n\u001b[0;32m    190\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_tts_model_by_path\u001b[39m(\n\u001b[0;32m    191\u001b[0m     \u001b[38;5;28mself\u001b[39m, model_path: \u001b[38;5;28mstr\u001b[39m, config_path: \u001b[38;5;28mstr\u001b[39m, vocoder_path: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, vocoder_config: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, gpu: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    192\u001b[0m ):\n\u001b[0;32m    193\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Load a model from a path.\u001b[39;00m\n\u001b[0;32m    194\u001b[0m \n\u001b[0;32m    195\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    200\u001b[0m \u001b[38;5;124;03m        gpu (bool, optional): Enable/disable GPU. Some models might be too slow on CPU. Defaults to False.\u001b[39;00m\n\u001b[0;32m    201\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 203\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msynthesizer \u001b[38;5;241m=\u001b[39m \u001b[43mSynthesizer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    204\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtts_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    205\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtts_config_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    206\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtts_speakers_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    207\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtts_languages_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    208\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvocoder_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvocoder_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    209\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvocoder_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvocoder_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    210\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    211\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    212\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_cuda\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgpu\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    213\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\Projects\\venv2\\lib\\site-packages\\TTS\\utils\\synthesizer.py:93\u001b[0m, in \u001b[0;36mSynthesizer.__init__\u001b[1;34m(self, tts_checkpoint, tts_config_path, tts_speakers_file, tts_languages_file, vocoder_checkpoint, vocoder_config, encoder_checkpoint, encoder_config, vc_checkpoint, vc_config, model_dir, voice_dir, use_cuda)\u001b[0m\n\u001b[0;32m     90\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available(), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCUDA is not availabe on this machine.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     92\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tts_checkpoint:\n\u001b[1;32m---> 93\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_load_tts\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtts_checkpoint\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtts_config_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_cuda\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     94\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_sample_rate \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtts_config\u001b[38;5;241m.\u001b[39maudio[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msample_rate\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m     96\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m vocoder_checkpoint:\n",
      "File \u001b[1;32mD:\\Projects\\venv2\\lib\\site-packages\\TTS\\utils\\synthesizer.py:187\u001b[0m, in \u001b[0;36mSynthesizer._load_tts\u001b[1;34m(self, tts_checkpoint, tts_config_path, use_cuda)\u001b[0m\n\u001b[0;32m    184\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtts_config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muse_phonemes\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtts_config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mphonemizer\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    185\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPhonemizer is not defined in the TTS config.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 187\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtts_model \u001b[38;5;241m=\u001b[39m \u001b[43msetup_tts_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtts_config\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    189\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder_checkpoint:\n\u001b[0;32m    190\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_speaker_encoder_paths_from_tts_config()\n",
      "File \u001b[1;32mD:\\Projects\\venv2\\lib\\site-packages\\TTS\\tts\\models\\__init__.py:13\u001b[0m, in \u001b[0;36msetup_model\u001b[1;34m(config, samples)\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     12\u001b[0m     MyModel \u001b[38;5;241m=\u001b[39m find_module(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTTS.tts.models\u001b[39m\u001b[38;5;124m\"\u001b[39m, config\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mlower())\n\u001b[1;32m---> 13\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mMyModel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minit_from_config\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msamples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msamples\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "File \u001b[1;32mD:\\Projects\\venv2\\lib\\site-packages\\TTS\\tts\\models\\vits.py:1796\u001b[0m, in \u001b[0;36mVits.init_from_config\u001b[1;34m(config, samples, verbose)\u001b[0m\n\u001b[0;32m   1791\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m (\n\u001b[0;32m   1792\u001b[0m         upsample_rate \u001b[38;5;241m==\u001b[39m effective_hop_length\n\u001b[0;32m   1793\u001b[0m     ), \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m [!] Product of upsample rates must be equal to the hop length - \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mupsample_rate\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m vs \u001b[39m\u001b[38;5;132;01m{\u001b[39;00meffective_hop_length\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1795\u001b[0m ap \u001b[38;5;241m=\u001b[39m AudioProcessor\u001b[38;5;241m.\u001b[39minit_from_config(config, verbose\u001b[38;5;241m=\u001b[39mverbose)\n\u001b[1;32m-> 1796\u001b[0m tokenizer, new_config \u001b[38;5;241m=\u001b[39m \u001b[43mTTSTokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minit_from_config\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1797\u001b[0m speaker_manager \u001b[38;5;241m=\u001b[39m SpeakerManager\u001b[38;5;241m.\u001b[39minit_from_config(config, samples)\n\u001b[0;32m   1798\u001b[0m language_manager \u001b[38;5;241m=\u001b[39m LanguageManager\u001b[38;5;241m.\u001b[39minit_from_config(config)\n",
      "File \u001b[1;32mD:\\Projects\\venv2\\lib\\site-packages\\TTS\\tts\\utils\\text\\tokenizer.py:198\u001b[0m, in \u001b[0;36mTTSTokenizer.init_from_config\u001b[1;34m(config, characters)\u001b[0m\n\u001b[0;32m    196\u001b[0m phonemizer_kwargs \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlanguage\u001b[39m\u001b[38;5;124m\"\u001b[39m: config\u001b[38;5;241m.\u001b[39mphoneme_language}\n\u001b[0;32m    197\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mphonemizer\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m config \u001b[38;5;129;01mand\u001b[39;00m config\u001b[38;5;241m.\u001b[39mphonemizer:\n\u001b[1;32m--> 198\u001b[0m     phonemizer \u001b[38;5;241m=\u001b[39m get_phonemizer_by_name(config\u001b[38;5;241m.\u001b[39mphonemizer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mphonemizer_kwargs)\n\u001b[0;32m    199\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    200\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32mD:\\Projects\\venv2\\lib\\site-packages\\TTS\\tts\\utils\\text\\phonemizers\\__init__.py:60\u001b[0m, in \u001b[0;36mget_phonemizer_by_name\u001b[1;34m(name, **kwargs)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Initiate a phonemizer by name\u001b[39;00m\n\u001b[0;32m     51\u001b[0m \n\u001b[0;32m     52\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;124;03m        Extra keyword arguments that should be passed to the phonemizer.\u001b[39;00m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     59\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mespeak\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m---> 60\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ESpeak(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     61\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgruut\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m     62\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Gruut(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mD:\\Projects\\venv2\\lib\\site-packages\\TTS\\tts\\utils\\text\\phonemizers\\espeak_wrapper.py:114\u001b[0m, in \u001b[0;36mESpeak.__init__\u001b[1;34m(self, language, backend, punctuations, keep_puncs)\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, language: \u001b[38;5;28mstr\u001b[39m, backend\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, punctuations\u001b[38;5;241m=\u001b[39mPunctuation\u001b[38;5;241m.\u001b[39mdefault_puncs(), keep_puncs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m    113\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ESPEAK_LIB \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 114\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m [!] No espeak backend found. Install espeak-ng or espeak to your system.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    115\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbackend \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ESPEAK_LIB\n\u001b[0;32m    117\u001b[0m     \u001b[38;5;66;03m# band-aid for backwards compatibility\u001b[39;00m\n",
      "\u001b[1;31mException\u001b[0m:  [!] No espeak backend found. Install espeak-ng or espeak to your system."
     ]
    }
   ],
   "source": [
    "tts=TTS(model_path=\"https://huggingface.co/Kamtera/persian-tts-male1-vits/resolve/main/checkpoint_88000.pth\",\n",
    "        config_path=\"https://huggingface.co/Kamtera/persian-tts-male1-vits/resolve/main/config.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Generate Persian speech\n",
    "tts.tts_to_file(text=\"سلام، حال شما چطور است؟\", file_path=\"persian_tts.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://huggingface.co/Kamtera/persian-tts-male1-vits/resolve/main/checkpoint_88000.pth\n",
    "# https://huggingface.co/Kamtera/persian-tts-male1-vits/resolve/main/config.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > Using model: vits\n",
      " > Setting up Audio Processor...\n",
      " | > sample_rate:22050\n",
      " | > resample:False\n",
      " | > num_mels:80\n",
      " | > log_func:np.log10\n",
      " | > min_level_db:0\n",
      " | > frame_shift_ms:None\n",
      " | > frame_length_ms:None\n",
      " | > ref_level_db:None\n",
      " | > fft_size:1024\n",
      " | > power:None\n",
      " | > preemphasis:0.0\n",
      " | > griffin_lim_iters:None\n",
      " | > signal_norm:None\n",
      " | > symmetric_norm:None\n",
      " | > mel_fmin:0\n",
      " | > mel_fmax:None\n",
      " | > pitch_fmin:None\n",
      " | > pitch_fmax:None\n",
      " | > spec_gain:20.0\n",
      " | > stft_pad_mode:reflect\n",
      " | > max_norm:1.0\n",
      " | > clip_norm:True\n",
      " | > do_trim_silence:False\n",
      " | > trim_db:60\n",
      " | > do_sound_norm:False\n",
      " | > do_amp_to_db_linear:True\n",
      " | > do_amp_to_db_mel:True\n",
      " | > do_rms_norm:False\n",
      " | > db_level:None\n",
      " | > stats_path:None\n",
      " | > base:10\n",
      " | > hop_length:256\n",
      " | > win_length:1024\n",
      " > Text splitted to sentences.\n",
      "['.زندگی فقط یک بار است']\n",
      " > Processing time: 0.9282166957855225\n",
      " > Real-time factor: 0.3134522503992706\n"
     ]
    }
   ],
   "source": [
    "from TTS.config import load_config\n",
    "from TTS.utils.manage import ModelManager\n",
    "from TTS.utils.synthesizer import Synthesizer\n",
    "\n",
    "persian_output_path = r\"C:\\Users\\User_1\\Desktop\\persian_tts.wav\"\n",
    "\n",
    "model_path = r\"D:\\Git_repos\\DeepNoiseReducer\\models\\PersianTTS\\best_model_65633.pth\"\n",
    "config_path = r\"D:\\Git_repos\\DeepNoiseReducer\\models\\PersianTTS\\config-0.json\"\n",
    "\n",
    "text=\".زندگی فقط یک بار است\"\n",
    "# text=\"hello\"\n",
    "\n",
    "synthesizer = Synthesizer(\n",
    "    model_path, config_path\n",
    ")\n",
    "wavs = synthesizer.tts(text)\n",
    "synthesizer.save_wav(wavs, persian_output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > Using model: vits\n",
      " > Setting up Audio Processor...\n",
      " | > sample_rate:22050\n",
      " | > resample:False\n",
      " | > num_mels:80\n",
      " | > log_func:np.log10\n",
      " | > min_level_db:0\n",
      " | > frame_shift_ms:None\n",
      " | > frame_length_ms:None\n",
      " | > ref_level_db:None\n",
      " | > fft_size:1024\n",
      " | > power:None\n",
      " | > preemphasis:0.0\n",
      " | > griffin_lim_iters:None\n",
      " | > signal_norm:None\n",
      " | > symmetric_norm:None\n",
      " | > mel_fmin:0\n",
      " | > mel_fmax:None\n",
      " | > pitch_fmin:None\n",
      " | > pitch_fmax:None\n",
      " | > spec_gain:20.0\n",
      " | > stft_pad_mode:reflect\n",
      " | > max_norm:1.0\n",
      " | > clip_norm:True\n",
      " | > do_trim_silence:False\n",
      " | > trim_db:60\n",
      " | > do_sound_norm:False\n",
      " | > do_amp_to_db_linear:True\n",
      " | > do_amp_to_db_mel:True\n",
      " | > do_rms_norm:False\n",
      " | > db_level:None\n",
      " | > stats_path:None\n",
      " | > base:10\n",
      " | > hop_length:256\n",
      " | > win_length:1024\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'TTS' object has no attribute 'is_multi_lingual'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 13\u001b[0m\n\u001b[0;32m      9\u001b[0m text\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mزندگی فقط یک بار است از آن به خوبی استفاده کن\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     11\u001b[0m tts\u001b[38;5;241m=\u001b[39mTTS(model_path\u001b[38;5;241m=\u001b[39mmodel_path,\n\u001b[0;32m     12\u001b[0m         config_path\u001b[38;5;241m=\u001b[39mconfig_path)\n\u001b[1;32m---> 13\u001b[0m \u001b[43mtts\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtts_to_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfile_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpersian_output_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\Projects\\venv2\\lib\\site-packages\\TTS\\api.py:332\u001b[0m, in \u001b[0;36mTTS.tts_to_file\u001b[1;34m(self, text, speaker, language, speaker_wav, emotion, speed, pipe_out, file_path, split_sentences, **kwargs)\u001b[0m\n\u001b[0;32m    290\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtts_to_file\u001b[39m(\n\u001b[0;32m    291\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    292\u001b[0m     text: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    301\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    302\u001b[0m ):\n\u001b[0;32m    303\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Convert text to speech.\u001b[39;00m\n\u001b[0;32m    304\u001b[0m \n\u001b[0;32m    305\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    330\u001b[0m \u001b[38;5;124;03m            Additional arguments for the model.\u001b[39;00m\n\u001b[0;32m    331\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 332\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_arguments(speaker\u001b[38;5;241m=\u001b[39mspeaker, language\u001b[38;5;241m=\u001b[39mlanguage, speaker_wav\u001b[38;5;241m=\u001b[39mspeaker_wav, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    334\u001b[0m     wav \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtts(\n\u001b[0;32m    335\u001b[0m         text\u001b[38;5;241m=\u001b[39mtext,\n\u001b[0;32m    336\u001b[0m         speaker\u001b[38;5;241m=\u001b[39mspeaker,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    340\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    341\u001b[0m     )\n\u001b[0;32m    342\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msynthesizer\u001b[38;5;241m.\u001b[39msave_wav(wav\u001b[38;5;241m=\u001b[39mwav, path\u001b[38;5;241m=\u001b[39mfile_path, pipe_out\u001b[38;5;241m=\u001b[39mpipe_out)\n",
      "File \u001b[1;32mD:\\Projects\\venv2\\lib\\site-packages\\TTS\\api.py:228\u001b[0m, in \u001b[0;36mTTS._check_arguments\u001b[1;34m(self, speaker, language, speaker_wav, emotion, speed, **kwargs)\u001b[0m\n\u001b[0;32m    226\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_multi_speaker \u001b[38;5;129;01mand\u001b[39;00m (speaker \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m speaker_wav \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    227\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel is multi-speaker but no `speaker` is provided.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 228\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_multi_lingual\u001b[49m \u001b[38;5;129;01mand\u001b[39;00m language \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    229\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel is multi-lingual but no `language` is provided.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    230\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_multi_speaker \u001b[38;5;129;01mand\u001b[39;00m speaker \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvoice_dir\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m kwargs:\n",
      "File \u001b[1;32mD:\\Projects\\venv2\\lib\\site-packages\\torch\\nn\\modules\\module.py:1709\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   1707\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m modules:\n\u001b[0;32m   1708\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m modules[name]\n\u001b[1;32m-> 1709\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'TTS' object has no attribute 'is_multi_lingual'"
     ]
    }
   ],
   "source": [
    "from TTS.api import TTS\n",
    "\n",
    "persian_output_path = r\"C:\\Users\\User_1\\Desktop\\persian_tts.wav\"\n",
    "\n",
    "model_path = r\"D:\\Git_repos\\DeepNoiseReducer\\models\\PersianTTS\\checkpoint_88000.pth\"\n",
    "config_path = r\"D:\\Git_repos\\DeepNoiseReducer\\models\\PersianTTS\\config.json\"\n",
    "\n",
    "\n",
    "text=\"زندگی فقط یک بار است از آن به خوبی استفاده کن\"\n",
    "\n",
    "tts=TTS(model_path=model_path,\n",
    "        config_path=config_path)\n",
    "tts.tts_to_file(text, file_path=persian_output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > Using model: vits\n",
      " > Setting up Audio Processor...\n",
      " | > sample_rate:22050\n",
      " | > resample:False\n",
      " | > num_mels:80\n",
      " | > log_func:np.log10\n",
      " | > min_level_db:0\n",
      " | > frame_shift_ms:None\n",
      " | > frame_length_ms:None\n",
      " | > ref_level_db:None\n",
      " | > fft_size:1024\n",
      " | > power:None\n",
      " | > preemphasis:0.0\n",
      " | > griffin_lim_iters:None\n",
      " | > signal_norm:None\n",
      " | > symmetric_norm:None\n",
      " | > mel_fmin:0\n",
      " | > mel_fmax:None\n",
      " | > pitch_fmin:None\n",
      " | > pitch_fmax:None\n",
      " | > spec_gain:20.0\n",
      " | > stft_pad_mode:reflect\n",
      " | > max_norm:1.0\n",
      " | > clip_norm:True\n",
      " | > do_trim_silence:False\n",
      " | > trim_db:60\n",
      " | > do_sound_norm:False\n",
      " | > do_amp_to_db_linear:True\n",
      " | > do_amp_to_db_mel:True\n",
      " | > do_rms_norm:False\n",
      " | > db_level:None\n",
      " | > stats_path:None\n",
      " | > base:10\n",
      " | > hop_length:256\n",
      " | > win_length:1024\n",
      " > Text splitted to sentences.\n",
      "['.زندگی فقط یک بار است']\n",
      " > Processing time: 1.933117151260376\n",
      " > Real-time factor: 0.29208168776238413\n",
      "<class 'str'> C:\\Users\\User_1\\AppData\\Local\\Temp\\tmp3je66s0a.wav\n"
     ]
    }
   ],
   "source": [
    "import tempfile ,os\n",
    "from TTS.utils.synthesizer import Synthesizer\n",
    "\n",
    "persian_output_path = r\"C:\\Users\\User_1\\Desktop\\persian_tts.wav\"\n",
    "\n",
    "model_path = r\"D:\\Git_repos\\DeepNoiseReducer\\models\\PersianTTS\\checkpoint_88000.pth\"\n",
    "config_path = r\"D:\\Git_repos\\DeepNoiseReducer\\models\\PersianTTS\\config.json\"\n",
    "\n",
    "text=\".زندگی فقط یک بار است\"\n",
    "\n",
    "synthesizer = Synthesizer(\n",
    "    model_path, config_path\n",
    ")\n",
    "\n",
    "wavs = synthesizer.tts(text)\n",
    "# return output\n",
    "with tempfile.NamedTemporaryFile(suffix=\".wav\", delete=False) as fp:\n",
    "    synthesizer.save_wav(wavs, fp)\n",
    "    print(type(fp.name), fp.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
