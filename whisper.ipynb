{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import whisper\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model (you can use \"base\", \"small\", \"medium\", or \"large\" for better accuracy)\n",
    "model = whisper.load_model(\"medium\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_path = r\"C:\\Users\\User_1\\Desktop\\Comm-sounds\\sat.mp3\"\n",
    "file_path = r\"C:\\Users\\User_1\\Desktop\\Comm-sounds\\1.mp3\"\n",
    "# file_path = r\"C:\\Users\\User_1\\Desktop\\Comm-sounds\\2.mp3\"\n",
    "# file_path = r\"C:\\Users\\User_1\\Desktop\\Comm-sounds\\3.mp3\"\n",
    "# file_path = r\"C:\\Users\\User_1\\Desktop\\Comm-sounds\\fa_1.m4a\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(' 300 checks. 300. Dangerous check stabilizers. Sit at 75%. Copy. Standing '\n",
      " 'by. DOB LPC, turn fine. Declining memory. Turn back for an unexpected A. Up '\n",
      " 'speed. DOB LPC, up speed successful with no unexpected errors. Copy, DOB. '\n",
      " 'You are clear for launch. And with that, shut down your visors. O2 on and '\n",
      " \"prepare for ignition, O2. Copy that and initiating a full 10-4-4. You've got \"\n",
      " 'to check two of your own. LT, L1 clear. Engines on. CP13, sector on. Wing '\n",
      " 'turning stable. O L H. Woo! Just getting the rock and roll. Over tone stage. '\n",
      " 'Alright, LL 60. Two minutes 45. Calling two engines manual. Copy, two '\n",
      " \"engines manual. Turning, we'll be back at 8.2, check. Standing by the full \"\n",
      " 'trails. Overlight deck chairs. On tour manual. 2.4, 2.8G right now and '\n",
      " 'counting. Access distortion negative one. Standby.')\n"
     ]
    }
   ],
   "source": [
    "# Transcribe Persian audio\n",
    "LANGUAGE = \"en\"\n",
    "# LANGUAGE = \"fa\"\n",
    "\n",
    "result = model.transcribe(file_path, language=LANGUAGE)\n",
    "\n",
    "# Print Persian transcription\n",
    "pprint(result[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-03-06 09:04:58\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mDF\u001b[0m | \u001b[1mLoading model settings of DeepFilterNet3\u001b[0m\n",
      "\u001b[32m2025-03-06 09:04:58\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mDF\u001b[0m | \u001b[1mUsing DeepFilterNet3 model at C:\\Users\\User_1\\AppData\\Local\\DeepFilterNet\\DeepFilterNet\\Cache\\DeepFilterNet3\u001b[0m\n",
      "\u001b[32m2025-03-06 09:04:58\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mDF\u001b[0m | \u001b[1mInitializing model `deepfilternet3`\u001b[0m\n",
      "\u001b[32m2025-03-06 09:04:58\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mDF\u001b[0m | \u001b[1mFound checkpoint C:\\Users\\User_1\\AppData\\Local\\DeepFilterNet\\DeepFilterNet\\Cache\\DeepFilterNet3\\checkpoints\\model_120.ckpt.best with epoch 120\u001b[0m\n",
      "\u001b[32m2025-03-06 09:04:58\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mDF\u001b[0m | \u001b[1mRunning on device cuda:0\u001b[0m\n",
      "\u001b[32m2025-03-06 09:04:58\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mDF\u001b[0m | \u001b[1mModel loaded\u001b[0m\n",
      "✅ Enhanced audio saved\n"
     ]
    }
   ],
   "source": [
    "import torchaudio\n",
    "import librosa\n",
    "import torch\n",
    "from df import enhance, init_df\n",
    "import soundfile as sf\n",
    "\n",
    "# Load DeepFilterNet model\n",
    "model, df_state, _ = init_df()  # Load default model\n",
    "\n",
    "# File path to your noisy MP3 file\n",
    "file_path = r\"C:\\Users\\User_1\\Desktop\\Comm-sounds\\2.mp3\"\n",
    "output_file_path = r\"C:\\Users\\User_1\\Desktop\\Comm-sounds\\output_1.wav\"\n",
    "\n",
    "# Load the audio file as a NumPy array\n",
    "noisy_audio, sr = librosa.load(file_path, sr=16000)  # Resample to 16kHz if needed\n",
    "\n",
    "# Convert to PyTorch tensor\n",
    "noisy_audio_tensor = torch.tensor(noisy_audio).unsqueeze(0)  # Add batch dimension\n",
    "\n",
    "# Enhance the audio\n",
    "enhanced_audio = enhance(model, df_state, noisy_audio_tensor)\n",
    "\n",
    "# Convert output to NumPy and save as WAV\n",
    "sf.write(output_file_path, enhanced_audio.squeeze().cpu().numpy(), sr)\n",
    "\n",
    "print(\"✅ Enhanced audio saved\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-03-06 09:17:14\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mDF\u001b[0m | \u001b[1mLoading model settings of DeepFilterNet3\u001b[0m\n",
      "\u001b[32m2025-03-06 09:17:14\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mDF\u001b[0m | \u001b[1mUsing DeepFilterNet3 model at C:\\Users\\User_1\\AppData\\Local\\DeepFilterNet\\DeepFilterNet\\Cache\\DeepFilterNet3\u001b[0m\n",
      "\u001b[32m2025-03-06 09:17:14\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mDF\u001b[0m | \u001b[1mInitializing model `deepfilternet3`\u001b[0m\n",
      "\u001b[32m2025-03-06 09:17:14\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mDF\u001b[0m | \u001b[1mFound checkpoint C:\\Users\\User_1\\AppData\\Local\\DeepFilterNet\\DeepFilterNet\\Cache\\DeepFilterNet3\\checkpoints\\model_120.ckpt.best with epoch 120\u001b[0m\n",
      "\u001b[32m2025-03-06 09:17:14\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mDF\u001b[0m | \u001b[1mRunning on device cuda:0\u001b[0m\n",
      "\u001b[32m2025-03-06 09:17:14\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mDF\u001b[0m | \u001b[1mModel loaded\u001b[0m\n",
      "✅ Strongly Enhanced Audio Saved as 'enhanced_output.wav'\n"
     ]
    }
   ],
   "source": [
    "import torchaudio\n",
    "import librosa\n",
    "import torch\n",
    "from df import enhance, init_df\n",
    "import soundfile as sf\n",
    "import torchaudio.functional as F\n",
    "\n",
    "# Load DeepFilterNet model\n",
    "model, df_state, _ = init_df()  # Ensure the model is correctly loaded\n",
    "\n",
    "# File path to your noisy MP3 file\n",
    "file_path = r\"C:\\Users\\User_1\\Desktop\\Comm-sounds\\sat.mp3\"\n",
    "output_file_path = r\"C:\\Users\\User_1\\Desktop\\Comm-sounds\\output_1.wav\"\n",
    "\n",
    "\n",
    "# Load the audio file using librosa\n",
    "noisy_audio, sr = librosa.load(file_path, sr=16000)  # Resample to 16kHz\n",
    "noisy_audio = librosa.util.normalize(noisy_audio)  # Normalize amplitude\n",
    "noisy_audio, _ = librosa.effects.trim(noisy_audio)  # Trim silence\n",
    "\n",
    "# Convert to PyTorch tensor and ensure the correct shape\n",
    "noisy_audio_tensor = torch.tensor(noisy_audio, dtype=torch.float32).unsqueeze(0)  # Shape: (1, samples)\n",
    "\n",
    "# Ensure model is in evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Apply DeepFilterNet Enhancement with stronger noise suppression\n",
    "enhanced_audio = enhance(model, df_state, noisy_audio_tensor, atten_lim_db=-40)  # Stronger filtering\n",
    "\n",
    "# Apply a high-pass filter to remove low-frequency noise\n",
    "enhanced_audio = torchaudio.functional.highpass_biquad(enhanced_audio, sr, cutoff_freq=200)  # Removes rumbling noise\n",
    "\n",
    "# Apply post-processing: Boost speech frequencies if needed\n",
    "enhanced_audio = F.gain(enhanced_audio, gain_db=12)  # Boost speech clarity\n",
    "\n",
    "# Save the enhanced audio as WAV\n",
    "sf.write(output_file_path, enhanced_audio.squeeze().cpu().numpy(), sr)\n",
    "\n",
    "print(\"✅ Strongly Enhanced Audio Saved as 'enhanced_output.wav'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
